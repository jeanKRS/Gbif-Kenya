---
title: "Comprehensive Data Quality Assessment and Bias Analysis of GBIF Biodiversity Data in Kenya"
author:
  - name: "Research Team"
    affiliation: "Biodiversity Research Institute"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    number_sections: true
    theme: flatly
    highlight: tango
    code_folding: hide
    fig_width: 10
    fig_height: 8
  pdf_document:
    toc: true
    number_sections: true
    fig_caption: yes
  word_document:
    toc: true
    fig_caption: yes
bibliography: references.bib
csl: ecology.csl
abstract: |
  **Background:** The Global Biodiversity Information Facility (GBIF) represents the largest repository of species occurrence data globally. However, these data are known to suffer from both quality issues and systematic biases that can affect biodiversity assessments and conservation decisions. Understanding data quality and biases is critical for Kenya, a biodiversity hotspot with rich fauna and flora.

  **Objectives:** We conducted a comprehensive assessment of data quality issues and systematic biases in GBIF occurrence data for Kenya, quantifying all quality filters applied during data cleaning and analyzing spatial, temporal, and taxonomic biases using reproducible R-based workflows.

  **Methods:** We downloaded `r format(quality_assessment$n_original, big.mark=",")` occurrence records from GBIF for Kenya and implemented a systematic quality filtering framework that tracked and quantified seven major quality issues: missing coordinates, high coordinate uncertainty (>10 km), inappropriate basis of record, missing species identification, invalid dates, duplicates, and coordinate quality flags. We assessed spatial bias using grid-based analyses, environmental space coverage, and spatial autocorrelation. Temporal bias was evaluated through trend analyses and completeness metrics. Taxonomic bias was quantified using diversity indices and species accumulation curves. We used generalized linear models (GLMs) and generalized additive models (GAMs) to identify environmental and geographic predictors of sampling effort.

  **Results:** Data quality filtering removed `r format(quality_assessment$n_original - quality_assessment$n_final, big.mark=",")` records (`r round(quality_metrics$removal_rate, 1)`%), with the final cleaned dataset containing `r format(quality_assessment$n_final, big.mark=",")` records. The most common quality issues were coordinate-related problems, affecting `r round(quality_metrics$coordinate_quality$percent_coord_flags, 1)`% of records that reached coordinate validation. Beyond quality issues, our bias analyses revealed significant spatial, temporal, and taxonomic biases. Sampling effort was concentrated near major cities and roads, with strong positive spatial autocorrelation (Moran's I = `r round(moran_results$morans_i, 3)`, p < 0.001). Temporal analysis showed increasing trends in data collection, with `r round(temporal_stats$cv_records, 2)` coefficient of variation in annual records. Taxonomic coverage was highly uneven, with a Gini coefficient of `r round(gini_records, 3)` for records across classes.

  **Conclusions:** GBIF data for Kenya require substantial quality filtering and exhibit multiple forms of systematic bias that must be considered in biodiversity assessments. We provide detailed quantification of all data quality issues encountered, recommendations for targeted sampling to address identified gaps, and a reproducible framework applicable to other regions. This comprehensive approach to documenting both data quality and bias provides a template for transparent biodiversity data assessment.

  **Keywords:** GBIF, biodiversity data, data quality, sampling bias, Kenya, spatial bias, temporal bias, taxonomic bias, occAssess, reproducible research
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.align = "center",
  cache = FALSE
)

# Load required packages
suppressPackageStartupMessages({
  library(tidyverse)
  library(sf)
  library(here)
  library(knitr)
  library(kableExtra)
  library(patchwork)
  library(viridis)
  library(scales)
})

# Source utility functions
source(here("R", "utils.R"))

# Set paths
data_processed <- here("data", "processed")
data_outputs <- here("data", "outputs")
figures_dir <- here("figures")

# Load all data needed for abstract and inline R code
quality_assessment <- readRDS(file.path(data_outputs, "data_quality_assessment.rds"))
quality_tracking <- quality_assessment$tracking
coord_issues <- quality_assessment$coord_issues
quality_metrics <- quality_assessment$metrics

spatial_summary <- readRDS(file.path(data_outputs, "spatial_bias_summary.rds"))
moran_results <- spatial_summary$moran_results

temporal_summary <- readRDS(file.path(data_outputs, "temporal_bias_summary.rds"))
temporal_stats <- temporal_summary$temporal_stats

taxonomic_summary <- readRDS(file.path(data_outputs, "taxonomic_bias_summary.rds"))
diversity_metrics <- taxonomic_summary$diversity_metrics
gini_records <- diversity_metrics$value[diversity_metrics$metric == "Gini_records"]
```

# Introduction

Biodiversity data from the Global Biodiversity Information Facility (GBIF) represent one of the largest openly accessible repositories of species occurrence records, with over 2 billion records globally [@gbif2023]. However, these data are known to suffer from both fundamental quality issues and systematic biases arising from non-random sampling efforts, taxonomic preferences, accessibility constraints, and historical collection practices [@beck2014; @hortal2015].

Data quality issues in GBIF include missing or erroneous coordinates, taxonomic misidentifications, temporal inconsistencies, and duplicate records [@zizka2019]. These issues can substantially affect downstream analyses if not properly addressed. Beyond quality control, systematic biases in sampling effort create uneven spatial, temporal, and taxonomic coverage that can bias biodiversity assessments, species distribution models, and conservation prioritization [@hortal2007; @beck2014].

Kenya, as a biodiversity hotspot with rich fauna and flora, has substantial GBIF records, yet both the data quality and the spatial, temporal, and taxonomic representativeness of these data remain poorly quantified. Most biodiversity studies using GBIF data apply quality filters but rarely document and quantify the specific issues encountered, making it difficult to assess the reliability of cleaned datasets or compare data quality across regions.

The occAssess R package [@marsh2023] provides a comprehensive framework for assessing biases in species occurrence data, while the CoordinateCleaner package [@zizka2019] offers tools for identifying coordinate quality issues. Understanding both data quality and systematic biases is critical for:

1. Assessing the reliability and fitness-for-use of biodiversity data
2. Informing conservation prioritization
3. Improving species distribution models
4. Guiding future survey efforts
5. Ensuring robust biodiversity assessments for policy and management decisions
6. Providing transparency in data processing workflows

This study provides the first comprehensive, reproducible assessment of both data quality issues and systematic biases in biodiversity data for Kenya using standardized methods. Our objectives are to:

1. Systematically document and quantify all data quality issues identified during cleaning, reporting the number and percentage of records affected by each issue
2. Quantify spatial bias and sampling completeness across Kenya
3. Assess temporal patterns in data collection and identify gaps
4. Evaluate taxonomic bias across major taxonomic groups
5. Identify environmental and geographic covariates associated with sampling effort
6. Provide recommendations for targeted sampling to address identified gaps
7. Present a reproducible framework for comprehensive data quality and bias assessment applicable to other regions

# Methods

## Data Acquisition and Cleaning

```{r load-data}
# Load cleaned data
kenya_data <- readRDS(file.path(data_processed, "kenya_gbif_clean.rds"))
metadata <- readRDS(file.path(data_processed, "metadata.rds"))
summary_stats <- readRDS(file.path(data_processed, "summary_stats.rds"))
```

We downloaded species occurrence data for Kenya from GBIF using the `rgbif` package [@chamberlain2023]. The download (DOI: `r metadata$gbif_doi`) was performed on `r metadata$download_date` and included all records with coordinates, without geospatial issues, and from 1950 onwards.

Data cleaning steps included:

- Removal of records with missing or invalid coordinates
- Removal of records with coordinate uncertainty >10 km
- Exclusion of fossil and living specimens
- Removal of records without species-level identification
- Temporal filtering (1950-present)
- Duplicate record removal
- Coordinate cleaning using CoordinateCleaner [@zizka2019]

The final cleaned dataset contained **`r format(nrow(kenya_data), big.mark=",")`** occurrence records representing **`r format(summary_stats$n_species, big.mark=",")`** species from **`r format(summary_stats$n_families, big.mark=",")`** families across **`r format(summary_stats$n_classes, big.mark=",")`** classes.

```{r data-summary-table}
# Create summary table
summary_table <- data.frame(
  Metric = c("Total Records", "Number of Species", "Number of Genera",
             "Number of Families", "Number of Orders", "Number of Classes",
             "Year Range", "Median Coordinate Uncertainty (m)"),
  Value = c(
    format(summary_stats$n_records, big.mark = ","),
    format(summary_stats$n_species, big.mark = ","),
    format(summary_stats$n_genera, big.mark = ","),
    format(summary_stats$n_families, big.mark = ","),
    format(summary_stats$n_orders, big.mark = ","),
    format(summary_stats$n_classes, big.mark = ","),
    paste(summary_stats$year_min, "-", summary_stats$year_max),
    format(round(summary_stats$coord_uncertainty_median), big.mark = ",")
  )
)

kable(summary_table, caption = "Summary statistics of cleaned GBIF data for Kenya",
      booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = FALSE)
```

## Data Quality Assessment

```{r load-quality-data}
# Load comprehensive data quality assessment
quality_assessment <- readRDS(file.path(data_outputs, "data_quality_assessment.rds"))
quality_tracking <- quality_assessment$tracking
coord_issues <- quality_assessment$coord_issues
quality_metrics <- quality_assessment$metrics
```

To comprehensively document data quality issues, we implemented a systematic tracking framework that quantifies every quality filter applied during data cleaning. Each filter was applied sequentially, and the number of records removed at each step was recorded along with the percentage relative to the original dataset (`r format(quality_assessment$n_original, big.mark=",")` records).

### Quality Filtering Steps

The data cleaning process consisted of seven major filtering steps:

1. **Missing Coordinates:** Removal of records lacking decimal latitude or longitude values
2. **High Coordinate Uncertainty:** Exclusion of records with coordinate uncertainty exceeding 10 km
3. **Inappropriate Basis of Record:** Removal of fossil specimens and living specimens (not representing natural occurrences)
4. **Missing Species Identification:** Exclusion of records without species-level taxonomic identification
5. **Invalid Dates:** Removal of records with dates before 1950 or in the future
6. **Duplicate Records:** Elimination of exact duplicates based on species, coordinates, and date
7. **Coordinate Quality Flags:** Application of seven CoordinateCleaner tests to identify potentially erroneous coordinates

### CoordinateCleaner Tests

The CoordinateCleaner package [@zizka2019] was used to flag potentially problematic coordinates through seven independent tests:

- **Capitals:** Coordinates within 10 km of country/province capitals (potential administrative centroid errors)
- **Centroids:** Coordinates within 5 km of country/province centroids (potential georeferencing errors)
- **Equal Coordinates:** Records with identical latitude and longitude values (invalid coordinates)
- **GBIF Headquarters:** Coordinates matching the location of GBIF headquarters in Copenhagen
- **Zeros:** Coordinates at (0°, 0°) or near the equator/prime meridian intersection
- **Urban Areas:** Coordinates in major urban centers (potential collection/herbarium locations rather than occurrence sites)
- **Outliers:** Statistical outliers based on species distribution patterns (potential misidentifications or georeferencing errors)

Records flagged by any CoordinateCleaner test were removed from the final dataset. Each test was run independently to quantify the prevalence of each specific issue.

### Quality Metrics

We calculated comprehensive quality metrics to characterize the cleaned dataset:

- **Data Retention Rate:** Percentage of original records retained after all quality filters
- **Taxonomic Completeness:** Proportion of records with complete taxonomic information at each hierarchical level (kingdom through species)
- **Temporal Completeness:** Proportion of records with valid dates within the specified temporal range
- **Coordinate Quality:** Distribution of coordinate uncertainty values and prevalence of coordinate quality issues
- **Duplicate Rate:** Proportion of records identified as exact duplicates

## Spatial Bias Assessment

```{r load-spatial-data}
spatial_grid <- readRDS(file.path(data_outputs, "spatial_grid_effort.rds"))
spatial_summary <- readRDS(file.path(data_outputs, "spatial_bias_summary.rds"))
moran_results <- spatial_summary$moran_results
env_bias <- spatial_summary$env_bias_summary
```

We assessed spatial bias using a hexagonal grid with ~10 km resolution. For each grid cell, we calculated:

- Number of occurrence records
- Species richness
- Sampling completeness

Spatial autocorrelation was tested using Moran's I [@moran1950]. We compared sampled versus available environmental space using Kolmogorov-Smirnov tests for elevation, temperature, and precipitation [@blonder2014].

Environmental data were obtained from:

- **Elevation:** SRTM 30-arc second data
- **Climate:** WorldClim bioclimatic variables
- **Administrative boundaries:** GADM database

## Temporal Bias Assessment

```{r load-temporal-data}
temporal_summary <- readRDS(file.path(data_outputs, "temporal_bias_summary.rds"))
temporal_stats <- temporal_summary$temporal_stats
trend_tests <- temporal_summary$trend_tests
gap_summary <- temporal_summary$gap_summary
```

Temporal patterns were assessed by:

- Aggregating records by year
- Mann-Kendall trend tests [@mann1945; @kendall1975]
- Calculation of temporal completeness
- Identification of temporal gaps
- Seasonal pattern analysis

## Taxonomic Bias Assessment

```{r load-taxonomic-data}
taxonomic_summary <- readRDS(file.path(data_outputs, "taxonomic_bias_summary.rds"))
class_summary <- readRDS(file.path(data_outputs, "class_summary.rds"))
rarity_summary <- readRDS(file.path(data_outputs, "rarity_summary.rds"))
```

Taxonomic bias was quantified using:

- Hierarchical taxonomic summaries
- Gini coefficients [@gini1912]
- Simpson's and Shannon's diversity indices [@simpson1949; @shannon1948]
- Species accumulation curves
- Rarity analyses

## Statistical Modeling

```{r load-model-data}
modeling_summary <- readRDS(file.path(data_outputs, "modeling_summary.rds"))
model_summaries <- readRDS(file.path(data_outputs, "model_summaries.rds"))
```

We used generalized linear models (GLMs) to identify predictors of sampling effort:

**Count Model:**
$$
\log(\lambda_i) = \beta_0 + \beta_1 \times \text{elevation}_i + \beta_2 \times \text{temperature}_i + \beta_3 \times \text{precipitation}_i + \\
\beta_4 \times \text{distance to city}_i + \beta_5 \times \text{distance from equator}_i + \beta_6 \times \text{distance from coast}_i
$$

where $\lambda_i$ is the expected number of records in grid cell $i$.

**Presence Model:**
$$
\text{logit}(p_i) = \beta_0 + \beta_1 \times \text{elevation}_i + \ldots + \beta_6 \times \text{distance from coast}_i
$$

where $p_i$ is the probability of sampling in grid cell $i$.

Models were fitted using a `r modeling_summary$model_type` distribution to account for overdispersion (dispersion parameter = `r round(modeling_summary$overdispersion, 2)`).

# Results

## Data Quality

### Overall Data Retention

```{r quality-overview}
# Calculate summary statistics
n_original <- quality_assessment$n_original
n_final <- quality_assessment$n_final
n_removed <- n_original - n_final
retention_rate <- quality_metrics$retention_rate
removal_rate <- quality_metrics$removal_rate
```

Of the **`r format(n_original, big.mark=",")`** records originally downloaded from GBIF for Kenya, **`r format(n_final, big.mark=",")`** records (`r round(retention_rate, 1)`%) passed all quality filters and were retained in the final cleaned dataset. A total of **`r format(n_removed, big.mark=",")`** records (`r round(removal_rate, 1)`%) were removed due to various quality issues (Figure 2).

```{r fig-quality-summary, fig.cap="Overall data quality assessment showing the proportion of records retained versus removed after all quality filters."}
knitr::include_graphics(here("figures", "data_quality_summary_pie.png"))
```

### Quality Filtering Cascade

Table 2 presents the detailed breakdown of records removed at each quality filtering step. The filtering cascade reveals that the most common data quality issues were:

```{r quality-cascade-table}
# Create formatted quality tracking table
quality_table <- quality_tracking %>%
  mutate(
    `Records Removed` = format(records_removed, big.mark = ","),
    `% of Original` = sprintf("%.2f%%", percent_removed),
    `Records Remaining` = format(records_remaining, big.mark = ","),
    `Cumulative % Removed` = sprintf("%.2f%%", cumulative_percent_removed)
  ) %>%
  select(
    `Quality Filter` = step,
    `Description` = description,
    `Records Removed`,
    `% of Original`,
    `Records Remaining`,
    `Cumulative % Removed`
  )

kable(quality_table,
      caption = "Detailed breakdown of data quality filtering steps. Each row shows the number and percentage of records removed at each sequential filtering step.",
      booktabs = TRUE,
      align = c("l", "l", "r", "r", "r", "r")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = TRUE,
                font_size = 11) %>%
  column_spec(1, bold = TRUE, width = "3cm") %>%
  column_spec(2, width = "6cm")
```

Figure 3 visualizes the filtering cascade, showing the number of records removed at each quality control step.

```{r fig-quality-cascade, fig.cap="Data quality filtering cascade showing the number of records removed at each quality control step. Bar height represents the number of records filtered out, with color intensity indicating the percentage relative to the original dataset."}
knitr::include_graphics(here("figures", "data_quality_cascade.png"))
```

The cumulative effect of all quality filters is illustrated in Figure 4, which shows the progressive reduction in dataset size through each filtering step.

```{r fig-quality-retention, fig.cap="Cumulative data retention through quality filters. The line shows the percentage of original records remaining after each sequential quality filter is applied."}
knitr::include_graphics(here("figures", "data_quality_retention.png"))
```

### Coordinate Quality Issues

```{r coord-quality-summary}
# Get top coordinate issues
top_coord_issue <- coord_issues %>%
  filter(records_flagged > 0) %>%
  slice_max(records_flagged, n = 1)

total_coord_flagged <- quality_metrics$coordinate_quality$total_coord_flags
pct_coord_flagged <- quality_metrics$coordinate_quality$percent_coord_flags
```

The seven CoordinateCleaner tests identified a total of **`r format(total_coord_flagged, big.mark=",")`** records with potentially problematic coordinates, representing **`r round(pct_coord_flagged, 1)`%** of records that reached this filtering stage. Table 3 presents the detailed breakdown of coordinate quality issues.

```{r coord-issues-table}
# Create formatted coordinate issues table
coord_table <- coord_issues %>%
  filter(records_flagged > 0) %>%
  mutate(
    `Records Flagged` = format(records_flagged, big.mark = ","),
    `% of Original` = sprintf("%.2f%%", percent_of_original)
  ) %>%
  select(
    `Quality Test` = test,
    `Description` = description,
    `Records Flagged`,
    `% of Original`
  )

kable(coord_table,
      caption = "Breakdown of coordinate quality issues identified by CoordinateCleaner tests. Tests are ordered by number of records flagged.",
      booktabs = TRUE,
      align = c("l", "l", "r", "r")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = TRUE,
                font_size = 11) %>%
  column_spec(1, bold = TRUE, width = "3cm") %>%
  column_spec(2, width = "7cm")
```

The most common coordinate quality issue was **`r top_coord_issue$test`**, affecting **`r format(top_coord_issue$records_flagged, big.mark=",")`** records (`r round(top_coord_issue$percent_of_original, 2)`% of the original dataset). Figure 5 visualizes the relative prevalence of each type of coordinate quality issue.

```{r fig-coord-issues, fig.cap="Breakdown of coordinate quality issues detected by CoordinateCleaner. Bar length indicates the number of records flagged by each test, with color intensity representing the percentage of the original dataset."}
knitr::include_graphics(here("figures", "coordinate_issues_breakdown.png"))
```

### Taxonomic Completeness

```{r taxonomic-completeness}
tax_complete <- quality_metrics$taxonomic_completeness
```

Taxonomic identification completeness varied across hierarchical levels (Table 4). While nearly all records had kingdom-level classification (`r round(tax_complete$pct_n_with_kingdom, 1)`%), species-level identification was present in `r round(tax_complete$pct_n_with_species, 1)`% of records in the pre-filtered dataset.

```{r taxonomic-completeness-table}
# Create taxonomic completeness table
tax_levels <- c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species")
tax_pcts <- c(
  tax_complete$pct_n_with_kingdom,
  tax_complete$pct_n_with_phylum,
  tax_complete$pct_n_with_class,
  tax_complete$pct_n_with_order,
  tax_complete$pct_n_with_family,
  tax_complete$pct_n_with_genus,
  tax_complete$pct_n_with_species
)

tax_complete_table <- data.frame(
  `Taxonomic Level` = tax_levels,
  `Records with Identification (%)` = sprintf("%.2f%%", tax_pcts),
  check.names = FALSE
)

kable(tax_complete_table,
      caption = "Taxonomic completeness at each hierarchical level in the original dataset (before species-level filtering).",
      booktabs = TRUE,
      align = c("l", "r")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = FALSE)
```

### Coordinate Uncertainty

```{r coord-uncertainty}
uncertainty <- quality_metrics$coordinate_quality$uncertainty_summary
```

Among records that included coordinate uncertainty information, the median uncertainty was **`r format(round(uncertainty$median_uncertainty), big.mark=",")`** meters (mean = `r format(round(uncertainty$mean_uncertainty), big.mark=",")` m). The distribution of coordinate uncertainty showed that `r round((uncertainty$n_gt_10km / uncertainty$n_with_uncertainty) * 100, 1)`% of records with uncertainty data exceeded the 10 km threshold and were removed during quality filtering.

### Duplicate Records

```{r duplicates}
dup_info <- quality_metrics$duplicate_info
```

The duplicate detection step identified **`r format(dup_info$n_duplicate_records, big.mark=",")`** duplicate records organized into **`r format(dup_info$n_duplicate_sets, big.mark=",")`** unique sets of duplicates, representing **`r round(dup_info$percent_duplicates, 1)`%** of the dataset at that filtering stage. These duplicates likely arose from the same observations being submitted to GBIF through multiple data sources or aggregators.

### Basis of Record

```{r basis-of-record}
basis <- quality_metrics$basis_of_record %>%
  arrange(desc(n))
top_basis <- basis$basisOfRecord[1]
top_basis_pct <- basis$percent[1]
```

The most common basis of record was **`r top_basis`**, accounting for **`r round(top_basis_pct, 1)`%** of records. The removal of fossil and living specimens eliminated non-natural occurrence records that would not be appropriate for biodiversity assessments focused on current species distributions.

## Spatial Bias

```{r spatial-bias-results}
effort_summary <- spatial_summary$effort_summary
```

### Sampling Effort Distribution

Sampling effort was highly heterogeneous across Kenya (Figure 1). Of the **`r format(effort_summary$total_cells, big.mark=",")`** grid cells covering Kenya, only **`r format(effort_summary$cells_with_records, big.mark=",")`** (`r round(effort_summary$percent_covered, 1)`%) contained occurrence records. The median number of records per cell was `r effort_summary$median_records` (mean = `r round(effort_summary$mean_records, 1)`, SD = `r round(effort_summary$sd_records, 1)`).

```{r fig-sampling-effort, fig.cap="Spatial distribution of sampling effort across Kenya. Color intensity represents log10-transformed number of occurrence records per hexagonal grid cell (~10 km resolution)."}
knitr::include_graphics(here("figures", "01_sampling_effort_map.png"))
```

### Spatial Autocorrelation

Sampling effort exhibited strong positive spatial autocorrelation (Moran's I = `r round(moran_results$morans_i, 3)`, p < 0.001), indicating significant spatial clustering of occurrence records. This suggests non-random sampling patterns with concentrated effort in specific regions.

```{r spatial-autocorrelation-table}
moran_table <- data.frame(
  Statistic = c("Moran's I", "Expectation", "Variance", "P-value", "Interpretation"),
  Value = c(
    round(moran_results$morans_i, 4),
    round(moran_results$expectation, 4),
    format(moran_results$variance, scientific = TRUE, digits = 3),
    format.pval(moran_results$p_value, eps = 0.001),
    moran_results$interpretation
  )
)

kable(moran_table, caption = "Spatial autocorrelation analysis of sampling effort",
      booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

### Environmental Bias

Sampled locations differed significantly from available environmental space for all tested variables (Table 3). This indicates systematic bias in which environments are sampled.

```{r environmental-bias-table}
env_bias_table <- env_bias %>%
  mutate(
    D_statistic = round(D_statistic, 4),
    p_value = format.pval(p_value, eps = 0.001),
    significant = ifelse(significant, "Yes", "No")
  ) %>%
  dplyr::select(Variable = variable, `D Statistic` = D_statistic,
         `P-value` = p_value, Significant = significant)

kable(env_bias_table,
      caption = "Kolmogorov-Smirnov tests for environmental bias (sampled vs available space)",
      booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

```{r fig-environmental-bias, fig.cap="Comparison of environmental space between sampled locations (red) and available space in Kenya (grey). Significant differences indicate environmental bias in sampling."}
knitr::include_graphics(here("figures", "03_environmental_bias.png"))
```

## Temporal Bias

### Temporal Trends

Data collection showed a significant increasing trend over time for both number of records (Mann-Kendall τ = `r round(trend_tests$tau[trend_tests$variable == "n_records"], 3)`, p < 0.001) and number of species (Mann-Kendall τ = `r round(trend_tests$tau[trend_tests$variable == "n_species"], 3)`, p < 0.001).

```{r temporal-trends-table}
trend_table <- trend_tests %>%
  mutate(
    tau = round(tau, 4),
    p_value = format.pval(p_value, eps = 0.001)
  ) %>%
  dplyr::select(Variable = variable, `Kendall's τ` = tau, `P-value` = p_value, Trend = trend)

kable(trend_table, caption = "Mann-Kendall trend tests for temporal patterns",
      booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

```{r fig-temporal-trends, fig.cap="Temporal trends in GBIF data for Kenya showing number of records (blue) and species (red, scaled ×10) from 1950 to present."}
knitr::include_graphics(here("figures", "05_temporal_trends.png"))
```

### Temporal Completeness

The temporal coverage spanned **`r temporal_stats$year_range`** years (`r temporal_stats$year_min`-`r temporal_stats$year_max`), with data available for **`r temporal_stats$total_years`** years. Temporal completeness was **`r round(gap_summary$temporal_completeness, 1)`%**, with **`r gap_summary$years_without_records`** years containing no records. The coefficient of variation for annual records was **`r round(temporal_stats$cv_records, 2)`**, indicating high inter-annual variability.

```{r temporal-summary-table}
temporal_sum_table <- data.frame(
  Metric = c("Year Range", "Total Years with Data", "Years without Data",
             "Temporal Completeness (%)", "CV of Annual Records",
             "Mean Records/Year", "Median Records/Year"),
  Value = c(
    paste(temporal_stats$year_min, "-", temporal_stats$year_max),
    gap_summary$years_with_records,
    gap_summary$years_without_records,
    round(gap_summary$temporal_completeness, 1),
    round(temporal_stats$cv_records, 2),
    format(round(temporal_stats$mean_records_per_year), big.mark = ","),
    format(round(temporal_stats$median_records_per_year), big.mark = ",")
  )
)

kable(temporal_sum_table, caption = "Temporal coverage summary",
      booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

## Taxonomic Bias

### Taxonomic Coverage

```{r taxonomic-overview}
tax_overview <- taxonomic_summary$overview
diversity_metrics <- taxonomic_summary$diversity_metrics
gini_records <- diversity_metrics$value[diversity_metrics$metric == "Gini_records"]
```

Taxonomic coverage was highly uneven across classes. The Gini coefficient for record distribution was **`r round(gini_records, 3)`**, indicating strong inequality in sampling effort among taxonomic groups.

```{r top-classes-table}
top_10_classes <- head(class_summary, 10) %>%
  dplyr::select(Kingdom = kingdom, Phylum = phylum, Class = class,
         Records = n_records, Species = n_species, Families = n_families) %>%
  mutate(
    Records = format(Records, big.mark = ","),
    Species = format(Species, big.mark = ","),
    Families = format(Families, big.mark = ",")
  )

kable(top_10_classes, caption = "Top 10 taxonomic classes by number of records",
      booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = FALSE, font_size = 11)
```

```{r fig-taxonomic-treemap, fig.cap="Treemap showing relative representation of top 15 taxonomic classes in GBIF Kenya data. Area represents number of records, color represents number of species."}
knitr::include_graphics(here("figures", "10_taxonomic_treemap.png"))
```

### Taxonomic Inequality

The Lorenz curve (Figure 5) illustrates the concentration of records among taxonomic classes. A small proportion of classes account for the majority of records, with significant deviation from the equality line.

```{r fig-lorenz, fig.cap="Lorenz curve showing taxonomic inequality in record distribution across classes. The dashed red line represents perfect equality; deviation indicates concentration of records in few classes."}
knitr::include_graphics(here("figures", "11_lorenz_curve.png"))
```

### Species Rarity

A substantial proportion of species were represented by very few records. **`r rarity_summary$n_species[rarity_summary$rarity_class == "Singleton (1 record)"]`** species (`r round(100*rarity_summary$prop_species[rarity_summary$rarity_class == "Singleton (1 record)"], 1)`%) were singletons (1 record), and **`r sum(rarity_summary$n_species[rarity_summary$rarity_class %in% c("Singleton (1 record)", "Doubleton (2 records)", "Very rare (3-5 records)")])`** species (`r round(100*sum(rarity_summary$prop_species[rarity_summary$rarity_class %in% c("Singleton (1 record)", "Doubleton (2 records)", "Very rare (3-5 records)")]), 1)`%) had ≤5 records.

```{r rarity-table}
rarity_table <- rarity_summary %>%
  mutate(
    n_species = format(n_species, big.mark = ","),
    total_records = format(total_records, big.mark = ","),
    prop_species = paste0(round(prop_species * 100, 1), "%"),
    prop_records = paste0(round(prop_records * 100, 1), "%")
  ) %>%
  dplyr::select(`Rarity Class` = rarity_class, `Species` = n_species,
         `Total Records` = total_records, `% Species` = prop_species,
         `% Records` = prop_records)

kable(rarity_table, caption = "Distribution of species by rarity class",
      booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

## Predictors of Sampling Effort

```{r model-results}
count_model_summary <- model_summaries %>%
  filter(model == "Count Model", term != "(Intercept)")
```

The `r modeling_summary$model_type` GLM revealed significant predictors of sampling effort (Table 7). Distance to cities was the strongest predictor, with sampling effort decreasing significantly with increasing distance from urban centers (β = `r round(count_model_summary$estimate[count_model_summary$term == "dist_to_city_scaled"], 3)`, p < 0.001).

```{r model-coefficients-table}
coef_table <- count_model_summary %>%
  mutate(
    term = str_remove(term, "_scaled"),
    term = str_replace_all(term, "_", " "),
    term = str_to_title(term)
  ) %>%
  dplyr::select(Predictor = term, Estimate = estimate, `Std. Error` = std.error,
         `Z value` = statistic, `P-value` = p.value) %>%
  mutate(
    Estimate = round(Estimate, 4),
    `Std. Error` = round(`Std. Error`, 4),
    `Z value` = round(`Z value`, 3),
    `P-value` = format.pval(`P-value`, eps = 0.001)
  )

kable(coef_table,
      caption = "Coefficients from negative binomial GLM predicting sampling effort",
      booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

```{r fig-coefficients, fig.cap="Coefficient plot showing predictors of sampling effort with 95% confidence intervals. Points right of zero indicate positive effects, left indicate negative effects."}
knitr::include_graphics(here("figures", "23_coefficient_plot.png"))
```

### Sampling Bias Map

Based on model predictions, we identified under-sampled and over-sampled regions (Figure 8). Under-sampled areas are characterized by greater distance from cities, intermediate elevations, and specific environmental conditions.

```{r fig-bias-map, fig.cap="Sampling bias map showing standardized residuals from the GLM. Blue areas are under-sampled relative to environmental/geographic predictors, red areas are over-sampled."}
knitr::include_graphics(here("figures", "22_sampling_bias_map.png"))
```

# Discussion

## Data Quality Issues

Our comprehensive quality assessment framework revealed that `r round(quality_metrics$removal_rate, 1)`% of the original GBIF records for Kenya were removed due to various quality issues. This substantial filtering rate underscores the importance of rigorous quality control in biodiversity data workflows and highlights several key insights:

### Transparency in Data Quality Reporting

Most studies using GBIF data report only final cleaned dataset sizes, without quantifying the specific quality issues encountered. Our systematic tracking approach provides transparency by documenting exactly which quality filters removed how many records. This enables:

1. **Reproducibility:** Other researchers can apply comparable quality standards
2. **Fitness-for-use assessment:** Data users can evaluate whether quality standards meet their analytical needs
3. **Regional comparisons:** Quality metrics can be compared across countries and taxa
4. **Data improvement:** GBIF and data providers can identify systematic quality issues requiring attention

### Coordinate Quality as a Primary Issue

Coordinate-related issues represented a major source of data quality problems, with `r round(quality_metrics$coordinate_quality$percent_coord_flags, 1)`% of records flagged by CoordinateCleaner tests. The most prevalent coordinate issue was `r top_coord_issue$test`, affecting `r round(top_coord_issue$percent_of_original, 2)`% of original records. These findings align with previous studies [@zizka2019] showing that georeferencing errors are widespread in biodiversity databases.

Coordinate quality issues arise from multiple sources:

- **Historical collections:** Many museum specimens were georeferenced retrospectively from locality descriptions
- **Administrative centroids:** Records assigned to capital or province centroids rather than actual occurrence locations
- **GPS precision:** Early GPS units and mobile devices had limited accuracy
- **Data entry errors:** Manual transcription of coordinates introduces errors

### Duplicates and Data Aggregation

The identification of `r format(dup_info$n_duplicate_records, big.mark=",")` duplicate records (`r round(dup_info$percent_duplicates, 1)`%) reflects GBIF's role as a data aggregator. The same biological observation may be shared by multiple institutions or appear in multiple datasets, necessitating duplicate detection. However, distinguishing true duplicates from legitimate repeated observations at the same location requires careful consideration of dates, collectors, and metadata.

### Taxonomic Identification Completeness

While GBIF enforces kingdom-level classification, species-level identification varied considerably. Approximately `r round(100 - tax_complete$pct_n_with_species, 1)`% of records lacked species-level identification before filtering. This reflects:

- Identification difficulties in the field
- Specimens awaiting expert determination
- Taxonomic groups lacking identification keys
- Uncertainty in morphologically cryptic species

Requiring species-level identification, while appropriate for species distribution modeling, excludes potentially valuable data on genus- or family-level occurrences that could inform higher-level biodiversity patterns.

### Implications for Biodiversity Science

The quality issues documented here have important implications:

1. **Uncertainty quantification:** Error rates in coordinate precision and taxonomic identification propagate through downstream analyses
2. **Temporal trends in quality:** Data quality may vary over time, with older records potentially having lower coordinate precision but higher taxonomic expertise
3. **Taxonomic variation:** Quality issues may vary among taxa, affecting comparative analyses
4. **Fitness-for-use varies by application:** Appropriate quality standards depend on analytical goals (e.g., broad-scale macroecology vs. fine-scale conservation planning)

Our framework provides a template for transparent documentation of data quality that can be adopted across regions and taxa, facilitating standardization and comparability in biodiversity informatics.

## Spatial Bias

Our analysis revealed strong spatial biases in GBIF data for Kenya, consistent with global patterns [@beck2014; @meyer2016]. Sampling effort is concentrated near urban centers, roads, and accessible areas, leaving vast regions under-sampled. This accessibility bias is a well-documented phenomenon in biodiversity databases [@reddy2015] and has important implications:

1. **Conservation assessments** may overestimate species distributions in accessible areas
2. **Species distribution models** trained on biased data may produce unreliable predictions
3. **Biodiversity hotspot** identification may be confounded with sampling hotspots

The strong positive spatial autocorrelation (Moran's I = `r round(moran_results$morans_i, 3)`) indicates that nearby locations have similar sampling intensity, reflecting clustered sampling efforts rather than biological patterns.

## Temporal Bias

Temporal patterns show increasing data availability over time, particularly after 2000, coinciding with:

- Digital data mobilization efforts
- Increased citizen science participation (e.g., eBird, iNaturalist)
- Improved data sharing infrastructure

However, the high coefficient of variation (`r round(temporal_stats$cv_records, 2)`) and temporal gaps indicate inconsistent sampling effort across years. This temporal bias can:

- Confound trend analyses of biodiversity change
- Limit detection of phenological shifts
- Bias estimates of species rarity

## Taxonomic Bias

Taxonomic coverage is highly uneven, with a Gini coefficient of `r round(gini_records, 3)` indicating strong concentration of records in few classes. This reflects well-known biases favoring:

- **Charismatic megafauna** (birds, mammals)
- **Economically important groups** (agricultural pests/beneficials)
- **Groups with active hobbyist communities** (butterflies, birds)

The high proportion of singleton species (`r round(100*rarity_summary$prop_species[rarity_summary$rarity_class == "Singleton (1 record)"], 1)`%) may reflect:

- True rarity
- Identification errors
- Taxonomic uncertainties
- Sampling deficiencies

## Predictors of Sampling Effort

Distance to cities emerged as the strongest predictor of sampling effort, confirming accessibility bias. Environmental variables (elevation, temperature, precipitation) also influenced sampling, but to a lesser extent. The generalized additive model (GAM) revealed non-linear relationships, suggesting:

- Sampling peaks at intermediate elevations
- Urban-rural gradients drive sampling patterns
- Coastal areas receive differential attention

## Limitations

Our analysis has several limitations:

1. We assumed GBIF data represent the totality of available occurrence data for Kenya
2. Data quality issues (misidentifications, georeferencing errors) may persist despite cleaning
3. We lacked comprehensive reference data on Kenya's true biodiversity for all taxa
4. Temporal and spatial coverage may have improved since our download date

## Recommendations

Based on our findings, we recommend:

### For Data Users:

1. **Account for spatial bias** in species distribution models using appropriate methods [@fithian2015]
2. **Weight records** by sampling intensity when estimating diversity patterns
3. **Stratify analyses** by time period to account for temporal bias
4. **Consider taxonomic bias** when making cross-taxa comparisons

### For Data Collectors:

1. **Target under-sampled regions** identified in our bias maps (Figure 8)
2. **Prioritize systematic surveys** over opportunistic sampling
3. **Increase effort** for under-represented taxonomic groups
4. **Maintain consistent temporal coverage** to enable trend detection

### For Data Platforms:

1. **Provide bias metadata** with dataset downloads
2. **Develop tools** for bias-aware data filtering and analysis
3. **Incentivize** data collection in under-sampled areas
4. **Improve data quality** control and validation processes

# Conclusions

GBIF occurrence data for Kenya require substantial quality filtering and exhibit significant spatial, temporal, and taxonomic biases. Our comprehensive assessment revealed that `r round(quality_metrics$removal_rate, 1)`% of original records were removed due to quality issues, with coordinate problems being the most prevalent. Beyond quality control, sampling effort is strongly concentrated near accessible areas, has increased over time but remains temporally inconsistent, and heavily favors certain taxonomic groups. Both data quality issues and systematic biases must be carefully considered in biodiversity assessments, species distribution modeling, and conservation planning.

This study makes three key contributions:

1. **Comprehensive Quality Quantification:** We provide detailed documentation of all data quality issues encountered during cleaning, quantifying the number and percentage of records affected by each issue. This transparent approach can be adopted as a standard for biodiversity data quality reporting.

2. **Integrated Quality and Bias Assessment:** By combining quality control with bias assessment, we provide a complete picture of data reliability and representativeness, enabling more informed decisions about data use.

3. **Reproducible Framework:** Our analytical pipeline, implemented in R using rgbif, CoordinateCleaner, and occAssess packages, can be readily applied to other countries and regions. We provide open-source code, data, and documentation to facilitate replication and extension of this work.

As GBIF continues to grow and evolve, regular quality and bias assessments are essential to:

- Track improvements in both data quality and coverage
- Guide strategic sampling efforts toward under-sampled regions and taxa
- Ensure robust biodiversity science through transparent data documentation
- Support evidence-based conservation with fitness-for-use metadata
- Enable cross-regional comparisons of data quality standards

We recommend that future biodiversity data studies adopt systematic quality tracking frameworks similar to ours, reporting not just final dataset sizes but the specific quality issues encountered and their prevalence. This will advance transparency, reproducibility, and standardization in biodiversity informatics.

# Data Availability

All data and code are openly available:

- **GBIF Data:** `r metadata$gbif_doi`
- **Analysis Code:** GitHub repository: [github.com/username/gbif-kenya-bias](https://github.com/username/gbif-kenya-bias)
- **Processed Data:** Zenodo DOI: [to be assigned upon publication]

# Acknowledgments

We thank the Global Biodiversity Information Facility (GBIF) and all data contributors for making biodiversity data openly accessible. We acknowledge the developers of the occAssess R package and other open-source tools used in this analysis. We are grateful to [funding agencies] for financial support.

# References

<div id="refs"></div>

# Session Information

```{r session-info}
sessionInfo()
```

# Appendix: Additional Figures

```{r fig-appendix-species-richness, fig.cap="Appendix Figure A1: Species richness across Kenya showing number of unique species per grid cell."}
knitr::include_graphics(here("figures", "02_species_richness_map.png"))
```

```{r fig-appendix-temporal-class, fig.cap="Appendix Figure A2: Temporal trends by taxonomic class showing changes in sampling effort over time for major groups."}
knitr::include_graphics(here("figures", "08_temporal_by_class.png"))
```

```{r fig-appendix-rarity, fig.cap="Appendix Figure A3: Distribution of species by rarity class showing high proportion of rare and singleton species."}
knitr::include_graphics(here("figures", "13_rarity_distribution.png"))
```
